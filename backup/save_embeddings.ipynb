{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e9c69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM libraries\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# Helper libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f04470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick a popular text model\n",
    "model_name = 'all-mpnet-base-v2' \n",
    "\n",
    "# We create the SentenceTransformer based on our model. This is the function that takes texts and produces embeddings.\n",
    "emb_model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b0282a",
   "metadata": {},
   "source": [
    "## Lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb4a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"https://raw.githubusercontent.com/nuitrcs/AI_Week_RAG/refs/heads/main/data/songs.csv\"\n",
    "lyrics = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just one line!!\n",
    "embeddings = emb_model.encode(lyrics['Lyrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766cd125",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('lyrics_embeddings.npy', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc92d9e",
   "metadata": {},
   "source": [
    "## Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a1b77",
   "metadata": {},
   "source": [
    "#### Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0054c605",
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_file = Path('../data/shakespeare_plays.csv')\n",
    "plays = pd.read_csv(shake_file, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e06997",
   "metadata": {},
   "source": [
    "full plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c9047e",
   "metadata": {},
   "outputs": [],
   "source": [
    "shake_embs = emb_model.encode(plays['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('shake_plays_embeddings.npy', shake_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694cfb39",
   "metadata": {},
   "source": [
    "subset of plays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426ca4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset_titles = ['King Lear', 'Macbeth', 'Othello', 'Romeo and Juliet', 'Hamlet']\n",
    "subset_titles_mini = ['King Lear', 'Othello']\n",
    "subset_plays = plays[plays['play_name'].isin(subset_titles_mini)]['text'].to_list()\n",
    "shake_subset_embs = emb_model.encode(subset_plays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5194e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('shake_subset_mini_plays_embeddings.npy', shake_subset_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4adf8f",
   "metadata": {},
   "source": [
    "#### wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a850dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = pd.read_csv('../data/wiki_subsample_k2500_n10k.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c65e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_embs = emb_model.encode(wiki['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea0bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('wiki_2500_embeddings.npy', wiki_embs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f5365a",
   "metadata": {},
   "source": [
    "### arxiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59e364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv = pd.read_csv('../data/arxiv_subsample_500.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cee989",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464264f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_embs_abstracts = emb_model.encode(arxiv['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ea289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_embs_text = emb_model.encode(arxiv['markdown'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f46036",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('arxiv_abstracts_embeddings.npy', arxiv_embs_abstracts)\n",
    "np.save('arxiv_text_embeddings.npy', arxiv_embs_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e360e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-workshop-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
